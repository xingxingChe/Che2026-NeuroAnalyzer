# -*- coding: utf-8 -*-
"""
CCH Master Pipeline (V_Console_Interactive_Fixed)
åŠŸèƒ½ï¼š
1. é›†æˆ Gaussian convolution ä¸ Jittering resamplingã€‚
2. æ”¯æŒå…¨è¿æ¥ç±»å‹ã€‚
3. ä¸¥æ ¼é’ˆå¯¹ CUMS / Control ç»„çš„çªè§¦å‰å•å‘é™é‡‡æ ·é¢„å¤„ç†ã€‚
4. ä¿®å¤äº† Gaussian Excitation é‡Œçš„ IndexErrorã€‚
5. å¢åŠ äº†å¯¹ "ctrl" ç­‰æ–‡ä»¶åçš„å…¼å®¹è¯†åˆ«ã€‚
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import convolve
from scipy.stats import poisson
from tqdm import tqdm
import tkinter as tk
from tkinter import filedialog
from datetime import datetime

# =========================================================================
# 1. é™é‡‡æ ·é¢„å¤„ç†å¼•æ“
# =========================================================================

TARGET_PYR_RATE = 6.765
TARGET_INT_RATE = 11.50

def downsample_spikes(spike_train, target_rate, total_recording_time):
    current_rate = len(spike_train) / total_recording_time
    if current_rate <= target_rate:
        return spike_train
    
    target_count = int(target_rate * total_recording_time)
    if target_count <= 0:
        return np.array([])
        
    downsampled = np.random.choice(spike_train, size=target_count, replace=False)
    downsampled.sort()
    return downsampled

# =========================================================================
# 2. é€šç”¨æ•°å­¦ä¸æ ¸å¿ƒ CCH å‡½æ•°
# =========================================================================

def calculate_cch(spike_train1, spike_train2, bin_size=0.0004, lag=0.05):
    num_bins = int(2 * lag / bin_size)
    if num_bins % 2 == 0: num_bins += 1
    bins = np.linspace(-lag, lag, num_bins + 1)
    
    all_diffs = []
    for t1 in spike_train1:
        relevant_t2 = spike_train2[(spike_train2 >= t1 - lag) & (spike_train2 <= t1 + lag)]
        all_diffs.append(relevant_t2 - t1)
        
    if all_diffs:
        all_diffs = np.concatenate(all_diffs)
        cch, _ = np.histogram(all_diffs, bins=bins)
    else:
        cch = np.zeros(num_bins)
    bin_centers = (bins[:-1] + bins[1:]) / 2
    return cch, bin_centers, bins

def fast_cch_for_jitter(pre_spikes, post_spikes, bins, lag):
    all_diffs = []
    for t1 in pre_spikes:
        relevant_t2 = post_spikes[(post_spikes >= t1 - lag) & (post_spikes <= t1 + lag)]
        if len(relevant_t2) > 0: all_diffs.append(relevant_t2 - t1)
    if all_diffs:
        all_diffs = np.concatenate(all_diffs)
        counts, _ = np.histogram(all_diffs, bins=bins)
        return counts
    return np.zeros(len(bins) - 1)

def create_hollow_gaussian(sigma_ms, hollow_fraction, bin_size_ms):
    sigma_bins = sigma_ms / bin_size_ms
    size = int(sigma_bins * 8)
    x = np.arange(-size, size + 1)
    gaussian = np.exp(-(x ** 2) / (2 * sigma_bins ** 2))
    hollow_gaussian = np.exp(-(x ** 2) / (2 * (sigma_bins * (1 - hollow_fraction)) ** 2))
    kernel = gaussian - hollow_gaussian
    return kernel / np.sum(kernel)

def calculate_baseline(cch, sigma=10, hollow_fraction=0.6, bin_size=0.4):
    kernel = create_hollow_gaussian(sigma, hollow_fraction, bin_size)
    return convolve(cch, kernel, mode='same')

def poisson_prob_continuity_corrected(n, mu):
    if mu <= 0: return 1.0 if n <= 0 else 0.0
    prob = 1 - poisson.cdf(n - 1, mu)
    return prob - 0.5 * poisson.pmf(n, mu)

# =========================================================================
# 3. ç»Ÿè®¡å­¦æ£€éªŒæ¨¡å—
# =========================================================================

def analyze_gaussian_excitation(cch, baseline, bins, pre_spike_count, p_syn_thresh=0.001, p_causal_thresh=0.0026):
    mono_window = (bins >= 0.0008) & (bins <= 0.0028)
    anti_causal_window = (bins >= -0.002) & (bins <= 0.0)
    n_syn, b_syn = np.sum(cch[mono_window]), np.sum(baseline[mono_window])
    n_anti = np.sum(cch[anti_causal_window])
    
    p_syn = poisson_prob_continuity_corrected(n_syn, b_syn)
    p_causal = poisson_prob_continuity_corrected(n_syn, n_anti)
    is_connected = (p_syn < p_syn_thresh) and (p_causal < p_causal_thresh)
    
    excess_spikes = n_syn - b_syn
    stp = (excess_spikes / pre_spike_count) if (pre_spike_count > 0 and excess_spikes > 0) else 0.0
    return is_connected, stp, p_syn, p_causal

def analyze_jitter_excitation(pre_spikes, post_spikes, n_iter=1000, jitter_window=0.005):
    raw_cch, bin_centers, bins_edges = calculate_cch(pre_spikes, post_spikes)
    surrogate_cchs = np.zeros((n_iter, len(raw_cch)))
    noise = np.random.uniform(-jitter_window, jitter_window, (n_iter, len(pre_spikes)))
    for i in range(n_iter):
        jittered_pre = np.sort(pre_spikes + noise[i, :])
        surrogate_cchs[i, :] = fast_cch_for_jitter(jittered_pre, post_spikes, bins_edges, 0.05)
        
    baseline_mean = np.mean(surrogate_cchs, axis=0)
    upper_bound = np.percentile(surrogate_cchs, 99.5, axis=0)
    window_mask = (bin_centers >= 0.0010) & (bin_centers <= 0.0040)
    is_connected = np.any(raw_cch[window_mask] > upper_bound[window_mask])
    
    excess_spikes = np.sum(raw_cch[window_mask]) - np.sum(baseline_mean[window_mask])
    stp = excess_spikes / len(pre_spikes) if (len(pre_spikes) > 0 and excess_spikes > 0) else 0.0
    return {"is_connected": is_connected, "metric": stp, "raw_cch": raw_cch, "baseline": baseline_mean, "bound": upper_bound, "bins": bin_centers}

def analyze_gaussian_inhibition(cch, baseline, bin_centers, pre_spike_count, p_thresh=0.001):
    mono_window = (bin_centers >= 0.0008) & (bin_centers <= 0.0030)
    n_obs, n_exp = np.sum(cch[mono_window]), np.sum(baseline[mono_window])
    
    if n_obs >= n_exp: return False, 0.0, 1.0
    p_val = poisson.cdf(n_obs, n_exp)
    is_inhibited = p_val < p_thresh
    
    deficit = n_exp - n_obs
    ssp = deficit / pre_spike_count if pre_spike_count > 0 else 0.0
    return is_inhibited, ssp, p_val

def analyze_jitter_inhibition(pre_spikes, post_spikes, n_iter=1000, jitter_window=0.005):
    raw_cch, bin_centers, bins_edges = calculate_cch(pre_spikes, post_spikes)
    surrogate_cchs = np.zeros((n_iter, len(raw_cch)))
    noise = np.random.uniform(-jitter_window, jitter_window, (n_iter, len(pre_spikes)))
    for i in range(n_iter):
        jittered_pre = np.sort(pre_spikes + noise[i, :])
        surrogate_cchs[i, :] = fast_cch_for_jitter(jittered_pre, post_spikes, bins_edges, 0.05)
        
    baseline_mean = np.mean(surrogate_cchs, axis=0)
    lower_bound = np.percentile(surrogate_cchs, 0.5, axis=0)
    window_mask = (bin_centers >= 0.0010) & (bin_centers <= 0.0040)
    is_inhibited = np.any(raw_cch[window_mask] < lower_bound[window_mask])
    
    deficit_spikes = np.sum(baseline_mean[window_mask]) - np.sum(raw_cch[window_mask])
    ssp = deficit_spikes / len(pre_spikes) if (len(pre_spikes) > 0 and deficit_spikes > 0) else 0.0
    return {"is_connected": is_inhibited, "metric": ssp, "raw_cch": raw_cch, "baseline": baseline_mean, "bound": lower_bound, "bins": bin_centers}

# =========================================================================
# 4. ç»Ÿä¸€ç»˜å›¾ä¸å¯¼å‡ºæ¨¡å—
# =========================================================================

def plot_and_save(bins, cch, baseline, bound, is_connected, metric, conn_type, algo, pair_id, animal_id, output_folder):
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ax = plt.subplots(figsize=(10, 6))
    bar_width = np.mean(np.diff(bins)) if len(bins)>1 else 0.0004
    
    is_exc = conn_type in ['PYR->INT', 'PYR->PYR']
    base_color = '#e74c3c' if is_exc else 'blue'
    fill_color = 'red' if is_exc else 'blue'
    window_color = 'orange' if is_exc else 'blue'
    win_min, win_max = (0.0008, 0.0028) if (algo == 'Gaussian' and is_exc) else (0.001, 0.004) if algo == 'Jittering' else (0.0008, 0.0030)
    
    ax.bar(bins, cch, width=bar_width, color='gray' if algo=='Jittering' else ('#2c3e50' if conn_type=='PYR->PYR' else 'black'), alpha=0.5 if algo=='Jittering' else 0.8, label='Raw CCH', edgecolor='none')
    ax.plot(bins, baseline, color='black' if algo=='Jittering' else base_color, linewidth=1.5 if algo=='Jittering' else 2, linestyle='--', label='Baseline')
    if bound is not None:
        ax.plot(bins, bound, color='red', linestyle='--', linewidth=1.2, label='Significance Bound')
        
    ax.axvspan(win_min, win_max, color=window_color, alpha=0.1, label=f'Analysis Window')
    
    if is_connected:
        window_mask = (bins >= win_min) & (bins <= win_max)
        if is_exc:
            ax.fill_between(bins[window_mask], cch[window_mask], baseline[window_mask], where=(cch[window_mask] > baseline[window_mask]), color=fill_color, alpha=0.6, label='Excess Spikes')
        else:
            ax.fill_between(bins[window_mask], cch[window_mask], baseline[window_mask], where=(baseline[window_mask] > cch[window_mask]), color=fill_color, alpha=0.6, label='Suppressed Spikes')

    ax.set_title(f"{conn_type} ({algo}): {animal_id} - {pair_id}", fontsize=14)
    ax.set_xlim(-0.05 if algo=='Gaussian' else -0.03, 0.05 if algo=='Gaussian' else 0.03)
    ax.legend(loc='upper right')
    
    status_str = f"{'Synapse' if is_exc else 'Suppression'} Detected\nMetric: {metric:.4f}" if is_connected else "No Connection"
    ax.text(0.95 if algo=='Gaussian' else 0.05, 0.95, status_str, transform=ax.transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right' if algo=='Gaussian' else 'left', bbox=dict(boxstyle='round', fc=fill_color if is_connected else 'gray', alpha=0.2))

    suffix = "Detected" if is_connected else "None"
    filename = f"{datetime.now().strftime('%Y%m%d')}_{algo}_{conn_type.replace('->','_')}_{animal_id}_{pair_id}_{suffix}.png"
    plt.savefig(os.path.join(output_folder, filename), dpi=300, bbox_inches='tight')
    plt.close(fig)

def save_numeric(data_dict, filename, output_folder):
    pd.DataFrame(data_dict).to_excel(os.path.join(output_folder, filename), index=False)


# =========================================================================
# 5. ä¸»ç¨‹åºä¸æ§åˆ¶å°å·¥ä½œæµ
# =========================================================================

def main():
    root = tk.Tk()
    root.withdraw() 
    
    print("\n=====================================================")
    print("ğŸŸ¢ CCH å…¨èƒ½åˆ†æå·¥ä½œç«™ (çº¯å‡€äº¤äº’ç‰ˆ) å·²å¯åŠ¨ï¼")
    print("ğŸ‘‰ ç¬¬ 1 æ­¥ï¼šè¯·åœ¨å¼¹å‡ºçš„çª—å£ä¸­é€‰æ‹©ã€åŸå§‹æ•°æ®æ–‡ä»¶å¤¹ã€‘ğŸ“‚")
    print("=====================================================")
    
    source_folder = filedialog.askdirectory(title="é€‰æ‹©åŒ…å«åŸå§‹æ•°æ® (.xlsx) çš„æ–‡ä»¶å¤¹")
    if not source_folder: 
        print("âŒ ä½ å–æ¶ˆäº†é€‰æ‹©ï¼Œç¨‹åºé€€å‡ºã€‚")
        return
    
    files_to_process = sorted([f for f in os.listdir(source_folder) if f.endswith('.xlsx')])
    if not files_to_process: 
        print("âŒ æ‰€é€‰æ–‡ä»¶å¤¹å†…æ²¡æœ‰æ‰¾åˆ° .xlsx æ–‡ä»¶ï¼Œç¨‹åºé€€å‡ºã€‚")
        return
        
    print(f"âœ… æˆåŠŸé”å®šåŒ…å« {len(files_to_process)} ä¸ª Excel æ–‡ä»¶çš„ç›®æ ‡æ–‡ä»¶å¤¹ï¼\n")
    print("ğŸ‘‰ ç¬¬ 2 æ­¥ï¼šè¯·é€‰æ‹©ã€ç»“æœä¿å­˜æ–‡ä»¶å¤¹ã€‘ğŸ“‚")
    output_folder = filedialog.askdirectory(title="é€‰æ‹©è¾“å‡ºç»“æœä¿å­˜æ–‡ä»¶å¤¹")
    if not output_folder: 
        print("âŒ ä½ å–æ¶ˆäº†é€‰æ‹©ï¼Œç¨‹åºé€€å‡ºã€‚")
        return
    
    print("âœ… è¾“å‡ºè·¯å¾„è®¾ç½®æˆåŠŸï¼\n")
    
    print("ğŸ‘‰ ç¬¬ 3 æ­¥ï¼šè¯·åœ¨ä¸‹æ–¹æ§åˆ¶å°ç›´æ¥è¾“å…¥å‚æ•°ï¼(ç›´æ¥æŒ‰å›è½¦ä»£è¡¨ä½¿ç”¨é»˜è®¤å¼€å¯/é»˜è®¤å€¼)")
    print("-----------------------------------------------------")
    
    while True:
        rec_time_str = input("â–¶ï¸ è¯·è¾“å…¥æ€»å½•éŸ³æ—¶é•¿ (ç§’) [é»˜è®¤ 600]: ").strip()
        if not rec_time_str:
            rec_time = 600.0
            break
        try:
            rec_time = float(rec_time_str)
            break
        except ValueError:
            print("âŒ è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥çº¯æ•°å­— (ä¾‹å¦‚ 600)ï¼")

    print("\nâ–¶ï¸ è¯·é€‰æ‹©åˆ†æç®—æ³• (è¾“å…¥ y å¼€å¯ï¼Œn å…³é—­ï¼Œç›´æ¥å›è½¦é»˜è®¤å¼€å¯):")
    run_gauss = input("   - è¿è¡Œ Gaussian Convolution? (y/n) [é»˜è®¤ y]: ").strip().lower() != 'n'
    run_jitter = input("   - è¿è¡Œ Jittering Resampling? (y/n) [é»˜è®¤ y]: ").strip().lower() != 'n'

    print("\nâ–¶ï¸ è¯·é€‰æ‹©è¦åˆ†æçš„è¿æ¥ç±»å‹ (è¾“å…¥ y å¼€å¯ï¼Œn å…³é—­ï¼Œç›´æ¥å›è½¦é»˜è®¤å¼€å¯):")
    c_pi = input("   - PYR (Pre) -> INT (Post) [Excitation] (y/n) [é»˜è®¤ y]: ").strip().lower() != 'n'
    c_ip = input("   - INT (Pre) -> PYR (Post) [Inhibition] (y/n) [é»˜è®¤ y]: ").strip().lower() != 'n'
    c_pp = input("   - PYR (Pre) -> PYR (Post) [Excitation] (y/n) [é»˜è®¤ y]: ").strip().lower() != 'n'
    c_ii = input("   - INT (Pre) -> INT (Post) [Inhibition] (y/n) [é»˜è®¤ y]: ").strip().lower() != 'n'

    conns = []
    if c_pi: conns.append(('PYR', 'INT'))
    if c_ip: conns.append(('INT', 'PYR'))
    if c_pp: conns.append(('PYR', 'PYR'))
    if c_ii: conns.append(('INT', 'INT'))
    
    if not conns or not (run_gauss or run_jitter): 
        print("âŒ æœªé€‰æ‹©æœ‰æ•ˆåˆ†æé…ç½®ï¼Œç¨‹åºé€€å‡ºã€‚")
        return

    print("\nâœ… å‚æ•°é…ç½®å®Œæ¯•ï¼å³å°†è¿›å…¥é«˜å¼ºåº¦è¿ç®—é˜¶æ®µ...")
    print("=====================================================\n")
    
    date_str = datetime.now().strftime('%Y%m%d')
    main_out_path = os.path.join(output_folder, f"{date_str}_Master_CCH_Analysis")
    os.makedirs(main_out_path, exist_ok=True)
    
    summary_data = []

    with tqdm(total=len(files_to_process), desc="Total Progress") as pbar_files:
        for filename in files_to_process:
            animal_id = os.path.splitext(filename)[0]
            animal_id_lower = animal_id.lower()
            
            # --- æ ¸å¿ƒé€»è¾‘ 1ï¼šè¯†åˆ«ç»„åˆ« (åŠ å…¥å¯¹ ctrl çš„è¯†åˆ«) ---
            if 'control' in animal_id_lower or 'con' in animal_id_lower or 'ctrl' in animal_id_lower: 
                group = 'Control'
            elif 'cums' in animal_id_lower: 
                group = 'CUMS'
            else: 
                group = 'Unknown'
                
            detail_folder = os.path.join(main_out_path, f"{animal_id}_Details")
            os.makedirs(detail_folder, exist_ok=True)
            
            tqdm.write(f"\nâ³ [è¯»å–ä¸­] æ­£åœ¨æ­»ç£•å¤§æ–‡ä»¶: {filename} (ç»„åˆ«è¢«è¯†åˆ«ä¸º: {group}) ...")
            df = pd.read_excel(os.path.join(source_folder, filename), header=None)
            tqdm.write(f"âœ… [è¯»å–å®Œæˆ] æˆåŠŸæå–ï¼å¼€å§‹ç­›é€‰æœ‰æ•ˆç¥ç»å…ƒå¹¶è®¡ç®— CCH...")
            
            neuron_ids, neuron_types = df.iloc[0, :].astype(str), df.iloc[1, :].astype(int)
            
            spikes_dict = {'PYR': {}, 'INT': {}}
            for i, n_type in enumerate(neuron_types):
                spk = df.iloc[2:, i].dropna().to_numpy()
                if len(spk) >= 500:
                    if n_type == 1: spikes_dict['PYR'][neuron_ids[i]] = spk
                    elif n_type == 0: spikes_dict['INT'][neuron_ids[i]] = spk

            for (pre_type, post_type) in conns:
                pre_ids = list(spikes_dict[pre_type].keys())
                post_ids = list(spikes_dict[post_type].keys())
                if not pre_ids or not post_ids: continue
                
                for pre_id in pre_ids:
                    for post_id in post_ids:
                        if pre_id == post_id: continue # é˜²æ­¢è‡ªç›¸å…³
                        
                        raw_pre_spikes = spikes_dict[pre_type][pre_id]
                        post_spikes = spikes_dict[post_type][post_id]
                        conn_name = f"{pre_type}->{post_type}"
                        pair_id = f"Pre{pre_type}_{pre_id}-Post{post_type}_{post_id}"
                        
                        # --- æ ¸å¿ƒé€»è¾‘ 2ï¼šæè‡´ä¸¥è°¨çš„çªè§¦å‰å•å‘é™é‡‡æ · ---
                        pre_spikes_analysis = raw_pre_spikes.copy()
                        if pre_type == 'PYR' and group == 'Control':
                            pre_spikes_analysis = downsample_spikes(raw_pre_spikes, TARGET_PYR_RATE, rec_time)
                        elif pre_type == 'INT' and group == 'CUMS':
                            pre_spikes_analysis = downsample_spikes(raw_pre_spikes, TARGET_INT_RATE, rec_time)

                        # è‹¥é™é‡‡æ ·åè„‰å†²å¤ªå°‘ï¼Œè·³è¿‡
                        if len(pre_spikes_analysis) < 100: 
                            continue 

                        # --- Pipeline A: Gaussian ---
                        if run_gauss:
                            cch, bins_centers, bins_edges = calculate_cch(pre_spikes_analysis, post_spikes)
                            baseline = calculate_baseline(cch)
                            
                            if pre_type == 'PYR': # Excitation (ä¿®å¤äº†æ­¤å¤„ä¼ å‚ä¸º bins_centers)
                                is_conn, metric, p1, p2 = analyze_gaussian_excitation(cch, baseline, bins_centers, len(pre_spikes_analysis))
                            else: # Inhibition
                                is_conn, metric, p_val = analyze_gaussian_inhibition(cch, baseline, bins_centers, len(pre_spikes_analysis))
                                
                            plot_and_save(bins_centers, cch, baseline, None, is_conn, metric, conn_name, 'Gaussian', pair_id, animal_id, detail_folder)
                            if is_conn:
                                summary_data.append({"Animal_ID": animal_id, "Group": group, "Connection": conn_name, "Pair": pair_id, "Method": "Gaussian", "Metric_STP_SSP": metric})
                                save_numeric({'Time': bins_centers, 'CCH': cch, 'Base': baseline}, f"{pair_id}_Gaussian_data.xlsx", detail_folder)

                        # --- Pipeline B: Jittering ---
                        if run_jitter:
                            if pre_type == 'PYR':
                                res = analyze_jitter_excitation(pre_spikes_analysis, post_spikes)
                            else:
                                res = analyze_jitter_inhibition(pre_spikes_analysis, post_spikes)
                                
                            plot_and_save(res['bins'], res['raw_cch'], res['baseline'], res['bound'], res['is_connected'], res['metric'], conn_name, 'Jittering', pair_id, animal_id, detail_folder)
                            if res['is_connected']:
                                summary_data.append({"Animal_ID": animal_id, "Group": group, "Connection": conn_name, "Pair": pair_id, "Method": "Jittering", "Metric_STP_SSP": res['metric']})
                                save_numeric({'Time': res['bins'], 'CCH': res['raw_cch'], 'Base': res['baseline'], 'Bound': res['bound']}, f"{pair_id}_Jitter_data.xlsx", detail_folder)
                                
            pbar_files.update(1)

    print("\n=====================================================")
    if summary_data:
        pd.DataFrame(summary_data).to_excel(os.path.join(main_out_path, f"{date_str}_Master_Summary.xlsx"), index=False)
        print("ğŸ‰ æ­å–œï¼å…¨ç³»åˆ—åˆ†æå®Œç¾æ”¶å®˜ï¼")
        print("ğŸ“‚ å·²ç”Ÿæˆæ€»è¡¨ï¼Œè¯·å‰å¾€ä½ é€‰æ‹©çš„è¾“å‡ºæ–‡ä»¶å¤¹æŸ¥çœ‹ã€‚")
    else:
        print("ğŸ›‘ åˆ†æç»“æŸï¼Œå½“å‰æ•°æ®é›†æœªæ£€æµ‹åˆ°ä»»ä½•æ˜¾è‘—çš„çªè§¦è¿æ¥ã€‚")
    print("=====================================================")

if __name__ == "__main__":
    main()